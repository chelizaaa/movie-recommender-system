# -*- coding: utf-8 -*-
"""Proyek Akhir Sistem Rekomendasi - Movie.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SmqbRhqLaoIc3ugHKA42AcCWoMRd_qmY

# **Proyek Akhir Sistem Rekomendasi**

Nama : Cheliza Sriayu Simarsoit  
E-mail : chelizasriayusimarsoit@gmail.com

# **1. Data Loading**

## 1.1 Kredensial Akun Kaggle

Pengaturan Kaggle Username dan Kaggle Key menggunakan library os untuk menghubungkan Kaggle dan Google Colab.

Dataset: [Movie Rating Dataset](https://www.kaggle.com/datasets/gargmanas/movierecommenderdataset)
"""

import os
os.environ['KAGGLE_USERNAME'] = 'chelizasriayu'
os.environ['KAGGLE_KEY'] = '89f42eb9dc5758b888995e5c2d0e16c5'

"""## 1.2 Download Dataset

Dataset yang digunakan adalah Movie Recommender System Dataset yang diambil dari platform Kaggle. File yang digunakan berupa file csv, yaitu `movies.csv` dan `ratings.csv`.
"""

!kaggle datasets download -d gargmanas/movierecommenderdataset

!unzip /content/movierecommenderdataset.zip

"""# **2. Data Understanding**

## 2.1 Jumlah Data dari Masing-masing Dataset

Membaca masing-masing dataset yaitu `movies.csv` dan `ratings.csv` menggunakan library pandas dari format .csv menjadi dataframe.
"""

import pandas as pd
 
movies = pd.read_csv('/content/movies.csv')
ratings = pd.read_csv('/content/ratings.csv')
 
print('Jumlah data movies: ', len(movies.movieId.unique()))
print('Jumlah data ratings: ', len(ratings.userId.unique()))

"""## 2.2 Univariate Exploratory Data Analysis (EDA)

Exploratory data analysis (EDA) merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data.

### 2.2.1 Dataset Movies

Pengecekan informasi variabel dari dataset movies yaitu jumlah kolom, nama kolom, jumlah data per kolom dan tipe datanya.
"""

movies.info()

"""Menampilkan banyaknya data movies dan genrenya."""

print('Banyak data: ', len(movies.movieId.unique()))
print('Genre: ', movies.genres.unique())

"""Menampilkan isi dataset movies."""

movies.head()

"""Pengecekan deskripsi statistik dataset movies dengan fungsi describe()."""

movies.describe()

"""### 2.2.2 Dataset Ratings

Pengecekan informasi variabel dari dataset ratings yaitu jumlah kolom, nama kolom, jumlah data per kolom dan tipe datanya.
"""

ratings.info()

"""Menampilkan banyaknya data ratings, jumlah user, dan rating film."""

print('Jumlah user: ', len(ratings.userId.unique()))
print('Jumlah rating: ', len(ratings))
print('Rating: ', ratings.rating.unique())

"""Menampilkan isi dataset ratings."""

ratings.head()

"""Pengecekan deskripsi statistik dataset ratings dengan fungsi describe()."""

ratings.describe()

"""# **3. Data Preprocessing**

Tahap data preprocessing adalah teknik yang digunakan untuk mengubah data mentah menjadi data yang bersih yang siap untuk digunakan pada proses selanjutnya.

## 3.1 Menggabungkan Data Movies dan Ratings

Menggabungkan dataset movies dan ratings menggunakan library Pandas merge pada kolom movieId.
"""

movierating = pd.merge(movies, ratings, on = 'movieId')
movierating.head()

"""# **4. Data Preparation**

Tahap data preparation merupakan proses transformasi data menjadi bentuk yang dapat diterima oleh model machine learning nanti. Proses data preparation yang dilakukan, yaitu membersihkan data missing value, melakukan pengecekan data duplikat, dan pemisahan genre pada dataset movie.

## 4.1 Pengecekan Missing Value

Melakukan pengecekan data yang hilang atau missing value menggunakan fungsi .isnull().sum().
"""

movies.isnull().sum()

ratings.isnull().sum()

movierating.isnull().sum()

"""## 4.2 Pengecekan Data Duplikat

Melakukan pengecekan data yang sama atau duplikat menggunakan fungsi duplicated().sum().
"""

print(f'Jumlah data movies yang duplikat: {movies.duplicated().sum()}')
print(f'Jumlah data rating yang duplikat: {ratings.duplicated().sum()}')
print(f'Jumlah data movierating yang duplikat: {movierating.duplicated().sum()}')

movies[movies.duplicated()]

ratings[ratings.duplicated()]

movierating[movierating.duplicated()]

"""## 4.3 Pemisahan Genre pada Dataset Movies

Melakukan pemisahan banyak genre yang tergabung pada dataset menjadi masing-masing genre terpisah.
"""

movies_new = movies.assign(genres=movies.genres.str.split('|')).explode('genres').reset_index(drop=True)
movies_new

"""# **5. Modeling**

Tahap pengembangan model machine learning atau modeling sistem rekomendasi dilakukan untuk memberikan hasil rekomendasi film terbaik kepada pengguna tertentu berdasarkan rating atau penilaian pengguna terhadap film tersebut. Tahap modeling yang dilakukan menggunakan teknik pendekatan content-based filtering recommendation dan collaborative filtering recommendation.
"""

movies = movies[:10000]
ratings = ratings[:5000]

"""## 5.1 Model Development dengan Content-based

Content-based filtering adalah teknik merekomendasikan item yang mirip dengan item yang disukai pengguna di masa lalu. Content-based filtering mempelajari profil minat pengguna baru berdasarkan data dari objek yang telah dinilai pengguna. Algoritma ini bekerja dengan menyarankan item serupa yang pernah disukai di masa lalu atau sedang dilihat di masa kini kepada pengguna. Semakin banyak informasi yang diberikan pengguna, semakin baik akurasi sistem rekomendasi.

### 5.1.1 TF-IDF Vectorizer

TF-IDF Vectorizer digunakan untuk menemukan representasi fitur penting dari setiap kategori film. TF-IDF Vectorizer dari library scikit-learn akan melakukan vektorisasi nilai dengan menggunakan metode fit_transform dan transform, serta melakukan tokenisasi data secara langsung.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()

tf.fit(movies_new['genres']) 

tf.get_feature_names()

"""Transformasi data film pada kolom genres menjadi bentuk verktor matriks."""

tfidf_matrix = tf.fit_transform(movies_new['genres']) 
tfidf_matrix.shape

"""Mengubah bentuk vectorizer yaitu vektor menjadi bentuk matriks."""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names_out(),
    index=movies_new.title
).sample(24, axis=1).sample(10, axis=0)

"""### 5.1.2 Cosine Similarity

Melakukan perhitungan derajat kesamaan atau similatiry degree antar judul film dengan teknik cosine similarity menggunakan library scikit-learn.
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""Mengubah matriks cosine similarity menjadi bentuk dataframe antar judul film."""

cosine_sim_df = pd.DataFrame(cosine_sim, index=movies_new['title'], columns=movies_new['title'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### 5.1.3 Recommendation Testing

Melakukan pendefinisian fungsi movies_recommendations untuk menampilkan hasil rekomendasi film berdasarkan kesamaan genre dari sebuah judul film.
"""

def movies_recommendations(nama_movie, similarity_data=cosine_sim_df, items=movies_new[['title', 'genres']], k=5):
    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(nama_movie, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

movie_title = 'Flint (2017)'
movies_new[movies_new.title.eq(movie_title)]

movies_recommendations(movie_title)

"""Berdasarkan hasil rekomendasi di atas, dapat dilihat bahwa sistem yang dibuat berhasil memberikan rekomendasi judul film berdasarkan sebuah judul film, yaitu 'Flint (2017)' dan dihasilkan rekomendasi judul film dengan genre film yang sama, yaitu drama.

## 5.2 Model Development dengan Collaborative Filtering

Collaborative Filtering adalah teknik merekomendasikan item yang mirip dengan preferensi pengguna yang sama di masa lalu, misalnya berdasarkan penilaian film yang telah diberikan oleh seorang pengguna. Sistem akan merekomendasikan film berdasarkan riwayat penilaian pengguna tersebut terhadap film dan genrenya.

### 5.2.1 Data Preparation
"""

import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""Proses encoding fitur userId pada dataset ratings menjadi array."""

user_ids = ratings['userId'].unique().tolist()
print('list userId: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

"""Proses encoding fitur movieId pada dataset ratings menjadi array."""

movies_ids = ratings['movieId'].unique().tolist()
movie_to_movie_encoded = {x: i for i, x in enumerate(movies_ids)}
movie_encoded_to_movie = {i: x for i, x in enumerate(movies_ids)}

"""Melakukan mapping atau pemetaan kolom user dan movie ke dataset ratings yang berkaitan."""

ratings['user'] = ratings['userId'].map(user_to_user_encoded)
ratings['movie'] = ratings['movieId'].map(movie_to_movie_encoded)

"""Melakukan pengecekan jumlah user, jumlah film, penilaian minimal, dan penilaian maksiaml."""

num_users = len(user_to_user_encoded)
print(num_users)
num_movie = len(movie_encoded_to_movie)
print(num_movie)

ratings['rating'] = ratings['rating'].values.astype(np.float32)

min_rating = min(ratings['rating'])
max_rating = max(ratings['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""### 5.2.2 Split Data Latih dan Data Validasi

Melakukan proses mengacak dataset ratings dengan fungsi .sample(frac=1).
"""

ratings = ratings.sample(frac=1, random_state=42)
ratings

"""Membagi dataset menjadi data latih (train) dan data uji (test), yaitu sebesar 20% data uji dan 80% data latih."""

x = ratings[['user', 'movie']].values
y = ratings['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * ratings.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""### 5.2.3 Model Development

Melakukan pendefinisian kelas RecommenderNet untuk membangun model klasifikasi teks tersebut.
"""

class RecommenderNet(tf.keras.Model):
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.movie_embedding = layers.Embedding(
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1)
    
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    movie_vector = self.movie_embedding(inputs[:, 1])
    movie_bias = self.movie_bias(inputs[:, 1])
    
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
    
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x)

"""Proses kompilasi atau compile dengan binary crossentropy loss function, adam optimizer, dan metrik RMSE (Root Mean Square Error)."""

model = RecommenderNet(num_users, num_movie, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics = [tf.keras.metrics.RootMeanSquaredError()]
)

"""Pelatihan model dengan fungsi .fit()."""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""Visualisasi grafik data training dan testing untuk masing-masing metrik Root Mean Square Error dan loss function."""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model error')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### 5.2.4 Tes Rekomendasi

Melakukan uji coba atau tes rekomendasi film yang diberikan. Namun perlu dikertahui terlebih dahulu untuk variabel khusus orang yang belum pernah menonton film tertentu menggunakan movie_not_watched.
"""

movie_df = movies
ratings_df = ratings

user_id = ratings_df.userId.sample(1).iloc[0]
movie_watched = ratings_df[ratings_df.userId == user_id]

movie_not_watched = movie_df[~movie_df['movieId'].isin(movie_watched.movieId.values)]['movieId'] 
movie_not_watched = list(
    set(movie_not_watched).intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

"""Melakukan pengujian prediksi hasil rekomendasi film berdasarkan judul film dan genre."""

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('=====' * 8)
print('Movie with high ratings from user')
print('-----' * 8)

top_movie_user = (
    movie_watched.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['movieId'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title, ':', row.genres)

print('-----' * 8)
print('Top 10 movie recommendation')
print('-----' * 8)

recommended_movie = movie_df[movie_df['movieId'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.genres)

"""Berdasarkan hasil rekomendasi film di atas, dapat dilihat bahwa sistem rekomendasi mengambil pengguna acak (19), lalu dilakukan pencarian film dengan rating terbaik dari user tersebut.

- Rear Window (1954) : **Mystery**|**Thriller**
- Heathers (1989) : **Comedy**
- Indiana Jones and the Last Crusade (1989) : **Action**|**Adventure**
- Ferris Bueller's Day Off (1986) : **Comedy**
- Who Framed Roger Rabbit? (1988) : **Adventure**|**Animation**|**Children**|**Comedy**|**Crime**|**Fantasy**|**Mystery**

Selanjutnya, sistem akan menampilkan 10 daftar film yang direkomendasikan berdasarkan genre yang dimiliki terhadap data pengguna acak tadi. Dapat dilihat bahwa sistem merekomendasikan beberapa film dengan genre yang sama, seperti

- Smoke (1995) : **Comedy**|**Drama**
- Fantasia (1940) : **Animation**|**Children**|**Fantasy**|**Musical**
- Amistad (1997) : **Drama**|**Mystery**
- Producers, The (1968) : **Comedy**
- The Lair of the White Worm (1988) : **Comedy**|**Horror**

# **6. Kesimpulan**

Dengan begitu, dapat disimpulkan bahwa sistem berhasil melakukan rekomendasi baik dengan pendekatan content-based filtering maupun collaborative filtering. Collaborative filtering membutuhkan data penilaian film dari pengguna, sedangkan pada content-based filtering, data rating tidak dibutuhkan karena sistem akan merekomendasikan berdasarkan konten film tersebut, yaitu genre.
"""